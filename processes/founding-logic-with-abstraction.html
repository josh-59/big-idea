<!doctype html>
<html lang="en">
<head>
	<meta charset="utf-8">
	<title>Founding Logic with Abstraction</title>
	<link href="../style.css" rel="stylesheet" type="text/css">
	<script>
	MathJax = {
		tex: {
			inlineMath: [['$', '$'], ['\\(', '\\)']]
		}
	};
	</script>
	<script type="text/javascript" id="MathJax-script" async
	src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
	</script>
</head>

<body>
	<header>
		<nav>
			<ul>
				<li> <a href="../"> Home </a></li>
				<li> <a href="./"> Processes </a></li>
				<li> <a href="../about.html"> About </a></li>
			</ul>
		</nav>

	</header>

	<br>

	<main>
		<h1> Founding Logic with Abstraction </h1>
		<h2> Introduction </h2>

		<p><em>The single most important component of clear thinking is being explicit.</em></p>

		<p>
			Many people have written about their interpretation of logic.
			This is mine.
			I will not attempt to produce a formal definition of logic.
			Rather, I will try to explain what the subject is about.
		</p>

		<p>
			Logic is about thinking clearly; it is, to some extent, a formal rendering of clear thought.
			As such, there are two characteristic features of logic.
			The first is being explicit, and
			the second is not presupposing connections.
		</p>

		<p>
			What we aim to do, in logic, is reconsider our own thinking.
			By considering our thinking in the abstract (without subject matter),
			we hope to establish the validity of our thought, then carry that
			validity back to the subject of our choosing.
		</p>

		<p>
			There are many logics.
			The standard logic of our time is, <em>First-Order Logic.</em>
			This logic is, "...a completely explicit theory of inference adequate to
			deal with all the standard examples of deductive reasoning in
			mathematics and the empirical sciences," (Suppes, xvi).
			This will be our pursuit.
		</p>

		<p>
			What I do have are some novel thoughts on the structure and purpose of the subject.
			In addition, I have a wish to develop First-Order Logic in common-sense terms, in part just
			to develop a personal understanding of it.
			So, think of this work as a study guide to logic.
		</p>

		<p>
			Another book on First-Order Logic that I will frequently reference is,
			<em>Language, Proof and Logic</em>, 2<sup>nd</sup> ed., by Dave Barker-Plumer,
			Jon Barwise, and John Etchemendy.
			I will refer to this work as <em>LPL.</em>
		</p>

		<h2> Objects </h2>

		<p>
			We begin with objects, because they are fundamental to first-order logic.
			Intuitively, an object is a <em>thing</em> that we may talk about.
			It's pretty important to have things to talk about&mdash;
			otherwise, you're just making noises!
			In a formal development, we consider each object
			individually and explicitly.
		</p>

		<p>
			An object is a well-defined abstraction.
			This means that it is a simplification (intuitively, a subset of all observable facets) of something else, with the caveat that
			it is unique:  There is exactly one.
			Objects transcend language;
			they belong to the mind alone.
		</p>

		<p>
			It's worth giving a few examples of objects, before proceeding.
			For instance, a pen is an object, as is a book.
			In particular, we make no distinction between objects that can be "realized by"
			some physical entity and those that cannot.
			Therefore, the color <em>blue</em> is an object just as much as <em>a bottle</em> is an object,
			for it is a well-defined abstraction.
		</p>

		<p>
			This uniformity is justified by my interpretation of mathematics:
			The number <em>two</em> is an object&mdash; specifically, it's a particular quantity&mdash;
			and the number two is not "realized by" any physical entity.
			Rather, it is a simplification away from the observation of multiple physical entities.
			That is, the number two is an abstraction.
		</p>

		<h2> Names </h2>
		<p>
			In order to talk about an object, it is necessary to have a tangible reference
			to it.
			The usual words are <em>symbol</em>, for the "tangible reference" part,
			and <em>denotes</em>, for the "refers to" part.
			For instance, the symbol $2$, as used above, denotes a quantity.
		</p>

		<p>
			Intuitively, symbols are names for objects.
			Formally, a symbol is a unique abstraction that refers to another abstraction.
			The situation can be likened to pointers in C:
		</p>

		<a href="img\pointer.png" title="Click for larger image"><img src="img/pointer.png"></a>

				<center><p style="font-size: small; width: 75%;"><em>
						In C, a </em>pointer<em> is a variable that hold the address of another
						variable.<sup><a href="#references">[1]</a></sup>
						Hence, if </em>p<em> is a pointer, and </em>x<em> and </em>y<em> are also variables,
						then we can arbitrarily assign to </em>p<em> the address of either </em>x<em> or </em>y<em> (or </em>p<em>), thereby giving ourselves a
						new, albeit indirect, handle to the memory implicitly referred to by </em>x<em> or </em>y<em> (or </em>p<em>).
				</em></p></center>

	<p>
		For further reading on names, see &#167;3.2, "Terms," and &#167;6.1, "Names and Things Named,"
		of <em>Introduction to Logic.</em>
	</p>

	<h2> Language </h2>

	<p>
		In making a clear distinction between symbols and objects,
		we have begun to carve out the ability to generate languages for ourselves.
		Specifically, we can assign any meaning we like to any symbol we like&mdash;
		that is, we can <em>define</em> symbols.
		Objects and symbols are used in mathematics and other empirical sciences to unambiguously assign meaning.
		For instance, within set theory, the symbol $$\emptyset$$ is defined to denote the empty set.
		If we were to define $\emptyset$ to denote some other object, then clearly
		we would be operating outside of set theory.
	</p>

	<p>
		To make ourselves explicit, the definition of a symbol  belong to <em>object languages.</em>


	<p>
		Because we have stipulated that a given symbol can at-most refer to a single object,
		we must restrict the scope of any symbol to be the language it has been
		defined in.
		Such a language we will call an <em>object language.</em>
		Once we have stipulated a symbol-object relation within an object language,
		we may assume that the symbol refers to that object
		throughout the entirety of that language; in other words, the uniqueness
		of a symbol-object relation is only formally recognized within a given object language.
	</p>

		<p>
			English, being a natural language, does not follow this rule.
			This is one of the reasons to develop formal languages,
			multiple-meanings being an avenue of ambiguity.
			In this case, English is used to describe; it is known as a <em>metalanguage.</em>
			A language that we describe with a metalanguage is called an <em>object language.</em>
			Set theory is an example of an object language.  See the first two chapters of
			<em>Axiomatic Set Theory</em> by Dr. Patrick Suppes, for more
			about object languages.
		</p>

		<p>
			Note that it <em>is not</em> the case that an object belongs to a language;
			moreover, it <em>is not</em> the case that each name belongs to a language.
			It is the definition which belongs to the language!
		</p>

		<li>
			<strong>Individual Constant:</strong>
			A name that is constant across the entirety of the language, and is not a <em>definite description.</em>
			For instance, the symbol $1$ is an <em>individual constant</em> in calculus.
		</li>

		<h2> Making Statements </h2>

		<p>
			Beyond symbols, object languages are also home to <em>predicates,</em>
			which allow us to make statements about objects.

		<p>
			Once given that objects may be named, there are a few things that one can say about them.
			The most elementary thing that one can say is that two names
			<em>denote the same</em> object; this is done through the much-maligned
			equals-sign, more appropriately thought of as <em>identity:</em>
		</p>

		$$
		a = b
		$$

		<p>
			The above says that $a$ refers to the same object as $b.$
		</p>

		<p>
			To give a concrete example, if we stipulate that the symbol $1$ denotes
			the set containing the empty set, then we arrive at the truism that,
		</p>

		$$
		1 = \{\{\}\}
		$$

		<p>
			I feel it prudent to reference the work of a more authoritative figure,
			when I claim that sameness of referent is the meaning of the equals-sign.
			So, on page 4 of <em>Axiomatic Set Theory</em>, Dr. Patrick Suppes has this to say:

			<div class="quote_text">
				"One [logical] principle used, concerning which there is some disagreement in practice
				among mathematicians, is that the double bar '=' is taken as the sign of identity.
				The formula '$x=y$' may be read '$x$ is the same as $y$',  '$x$ is identical with $y$'
				or '$x$ is equal to $y$'.  The last reading is permissible here only if it
				is understood that equality means sameness of identity (which is what it does mean in almost
				all ordinary mathematical contexts)."
			</div>
		</p>

		<p>
			A typical use of identity in mathematics is found in Walter Rudin's <em>Principles of Mathematical Analysis</em>.
			In the definition of an ordered set, we find:
		</p>

		<p> <strong> Definition </strong> Let $S$ be a set.  An <em>order</em> on $S$ is a relation, denoted by &lt;,
			with the following two properties:

			<ol>
				<li>
					If $x\in S$ and $y\in S$ then one and only one of the statements
					$$
					x < y, \hspace{2em} x = y, \hspace{2em} y < x
					$$
					is true.
				</li>
				<li>
					If $x, y, z \in S$, if $x < y$ and $y < z$, then $x < z$.
				</li>
			</ol>
		</p>

		<p>
			I interpret the first property as stating that, given any two elements of an ordered set, either one is larger than the
			other, or they are the same element;
			the second property stipulates transitivity.
			It should be noted that I will develop this logic only as long as it
			remains true to such mathematical statements.
		</p>

		<p>
			Both objects and names are mainstays of first-order languages;
			concurrently, <em>identity</em> is often included in first-order languages, and is
			often studied within first-order logic.
			However, note that because identity is a predicate, it does not <em>necessarily</em> belong
			to a given first-order language.
			As a consequence, it does not belong to first-order <em>logic</em>, per se,
			though it is usually developed there (for it is so common).
			For more on the subject of identity, see &#167;5.1, "Logic of Identity," of <em>Introduction to Logic.</em>
		</p>

		<p>
			This discussion has begun our study of predicates,
			and it is here that I begin to diverge from first-order logic.
			I define: A <em>predicate</em> is an individual constant that denotes a relation among objects,
			some of which may be fixed.
		<p>

		<p>
			A few examples of predicates:
			<ol>
				<li> $=$ </li>
				<li> $<$ </li>
				<li> <em>Is_Brother_Of</em></li>
			</ol>
		</p>

		<h2> Language </h2>



		<h2> Sentential / Truth-Functional Connectives </h2>

		<p>
			<em>Introduction to Logic</em>, Page 43:
				"We are not committed to developing a logic adequate to all the nuances of
				everyday language."

		<p>
			For example, the semantics of the implication are taught in most
			texts (including <em>Introduction to Logic</em>) not to depend upon
			any non-truth relation, so that a sentence like,
			$$
			\text{If the sky is blue, then } 2 + 2 = 4
			$$
			is considered a valid use of the implication connective.
			As proof, the above implication is considered <em>true</em>, by modern logicians.
		</p>

		<p>
			This is done for well-devised reasons:
			<ol>
				<li>Given a declarative sentence, we can always determine its truthity</li>
				<li>By defining implication in terms of truth-values, we can make its meaning explicit</li>
			</ol>

			Indirection (notes):
			https://en.wikipedia.org/wiki/Fundamental_theorem_of_software_engineering

			An example of poor indirection:
			Definition 16, Graph Theory
			"Are said to be"
		</p>

		<p>
			Another thing one can say about objects, which the developments of
			logic given above do not touch upon, is that one object may be contained in
			another object.
			Tentatively, we will define this as the <em>is</em> relation.
			We define:
			For any two objects $a$ and $b$, "$a$ <em>is</em> $b$" is true if and only
			if $b$ is a correct abstraction of $a.$
		</p>

		<p>
			This is used in natural language to make statements like, "That bottle is blue."
			The abstraction denoted by "bottle" contains the abstraction "blue,"
			and "blue" is a correct abstraction of the bottle;
			we might say things like, "Hand me that blue thing over there."
		</p>

		<h2> Implicit Definitions </h2>
		<p>
			In mathematics and all empirical sciences, it is customary to use
			explicit definitions wherever possible.
			This isn't always possible, and it isn't necessary, either.
			To define a symbol, we only require that it denote a unique abstraction.
			So, we can identity this abstraction indirectly, a technique often used in
			pure logic.
		</p>

		<p>
			For instance, the number $2$ is unambiguously identified by,
			"A natural number that is less than three and greater than one."
		</p>

		<h2>About</h2>

		<p>
			My other project, <a href="https://josh-59.github.io/Learning-Linux/">Learning Linux</a>,
			has been remarkably successful in teaching me about Linux.
			In addition, it's taught me to read works of all kinds, because the struggle in writing well
			about Linux has been in using language to express ideas, where the ideas are well-founded, and the language is variable.
			It seemed that a similar pattern was forming in the study of logic: That my own thoughts on logic
			exist, but are not sufficiently defined to be unambiguous, and therefore,
			progress in learning the subject has stalled.
		</p>

		<p>
			So, I endeavor to recapture the success of the Learning Linux project, in the study of logic.
			The two books I'm reading on logic are, <em>Language, Proof and Logic</em>, 2<sup>nd</sup> ed., by Dave Barker-Plumer,
			Jon Barwise & John Etchemendy; and
			<em>Introduction to Logic</em> by Patrick Suppes.
			I mention this because these, together, form the foundation of my studies about logic.
			<em>Language, Proof and Logic</em> is a contemporary work on the subject of logic; moreover,
			because it is the work of three authors, I feel that it represents well the subject as it
			is taught today.
			<em>Introduction to Logic</em> was written in 1957; although it is comparatively dated,
			Patrick Suppes is a remarkable author.
		</p>


		<h2> Abstraction Layer </h2>

		<p>
			So, all we have done is to make explicit the distinction between
			symbol and object.
			This is an example of an <em>abstraction layer.</em>
		</p>

		<h2> Other Kinds of Names </h2>

		<ul>
			<li>
				<strong>Definite Description:</strong>
				A description of an object which is sufficiently precise to function as a name.
				For example, the description, <em>"The set containing the empty set,"</em>
				is definite.
			</li>
			<li>
				<strong>Variable:</strong>
				A name that does not denote anything
			</li>
			<li>
				<strong>Term:</strong>
				An <em>individual constant,</em> a <em>variable,</em> or a <em>definite description.</em>
			</li>
			<li>
				<strong>Symbol:</strong>
				A term that is not a definite description.
			</li>
			<li>
				<strong>Referent:</strong>
				The object that a name denotes.
			</li>
		</ul>


        <div id="#references">
            <ol>
                <li> Kernighan, B. and Ritchie, D., 1988.  <em>The C Programming Language.</em> Englewood Cliffs, N.J.: Prentice Hall. </li>
            </ol>
        </div>


		<center> <a href="#">Top </a> </center>
	</p>

	<footer>
		Questions, comments, criticisms? <a href="mailto:josh.m.timmons@gmail.com" > Leave me feedback!</a>
	</footer>
</main>

</body>
</html>
